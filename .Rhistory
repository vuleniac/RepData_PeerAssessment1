plot(x = cars$speed, y = cars$dist, xlab="Speed", ylab="Stoppind Distance")
plot(x = cars$speed, y = cars$dist, ylab="Stoppind Distance")
plot(x = cars$speed, y = cars$dist, ylab="Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab="Speed", ylab="Stopping Distance")
plot(cars, main="My Plot")
plot(cars, sub="My Plot Subtitle")
plot(cars, col=2)
plot(cars, xlim = c(10, 15))
plot(cars, pch=2)
data(mtcars)
?boxplot
boxplot(formula=mpg~cyl, data=mtcars)
hist(mtcars$mpg)
hello
librarY(swirl)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors=F)
mydf <- read.csv(path2csv, stringsAsFactors=FALSE)
dim(mydf)
head(mydf,20)
head(mydf)
library(dplyr)
packageVersion("dyplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size> 100500 & r_os=="linux-gnu")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500 , r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(version))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
type arrange(cran2, ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package,mean(size))
submit()
ack_sum
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
submit()
submit()
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate( data = res, col = sex_class,into = c("sex", "class"))
submint()
submit()
students3
submit()
?spread
submit()
submit()
extract_numeric("class5")
submit()
submit()
students4
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
bind_rows(passed, failed)
sat
submit()
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- Today
this_day <- Today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, lable=T)
wday(this_day, label=T)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
minute(this_moment)
ymd("1989-05-17")
my-date <- ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
thi_moment <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment <- update(this_moment, hours = 20, minutes = 53, seconds = 55)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment <- update(this_moment, hours = 10, minutes = 54, seconds = 0)
this_moment <- update(this_moment, now())
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
his_moment <- update(this_moment, hours = 20, minutes = 57, seconds = 55)
update(this_moment, hours = 10, minutes = 16, seconds = 0)
0
play()
nxt()
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update( depart,  hours (17) , minutes (34))
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <-mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
new_interval(last_time, arrive)
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
?ddply
library(lubridate)
file_url='https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip'
## 1. Download: Checks the existance of the data from UCI Machine Learning Repository on Household Power Consumption.
##               If the data does not exist, downloads it and decompresses it.
if(!file.exists("./household_power_consumption.zip")){
download.file(file_url, destfile="./household_power_consumption.zip")
unzip("./household_power_consumption.zip",exdir=".")
}else{ if(!file.exists("./household_power_consumption.txt")){
unzip("./household_power_consumption.zip",exdir=".")}
}
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
str(nlme)
data(nlme)
?nlme
?BodyWeight
setwd("C:/Users/kvj39652/Desktop/ANALYTICS/COURSERA/DATA SCIENCE/COURSES/4. Exploratory Data Analysis/Projects/Week3")
# PLOT 1
## GETTING THE DATA
file_url='https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip'
### Checking the existance of the data
if(!file.exists("./summarySCC_PM25.rds")|!file.exists("./Source_Classification_Code.rds")){
if(!file.exists("./exdata-data-NEI_data.zip")){
download.file(file_url, destfile="./exdata-data-NEI_data.zip")
unzip("./exdata-data-NEI_data.zip",exdir=".")
}else{
unzip("./exdata-data-NEI_data.zip",exdir=".")
}
}
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
is.installed <- function(pck = NULL){
installed_pck <- as.character(rownames(installed.packages()))
if(is.null(pck)){
installed_pck
}else{
pck %in% installed_pck
}
}
required<- c("plyr", "ggplot2")
for(i in required){
if(is.installed(i)==T){
if(!is.element(i, .packages())) {
library(i, character.only = T, quietly = T,  verbose = F)
}
}else{
install.packages(i, quiet = T,  verbose = F)
library(i, character.only = T, quietly = T,  verbose = F)
}
}
sum_emissions<- ddply(NEI, "year", summarize,
sum = sum(Emissions, na.rm=T))
png(filename = "plot1.png", width=480, height=480)
barplot(sum_emissions$sum/1000000, col = rainbow(10, start = 0, end = 1), main = "Total PM_2.5 emissions (Tons)", names.arg=sum_emissions$year, ylab="Millions of Tons", xlab= "Year")
dev.off()
# PLOT 5
## GETTING THE DATA
file_url='https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip'
### Checking the existance of the data
if(!file.exists("./summarySCC_PM25.rds")|!file.exists("./Source_Classification_Code.rds")){
if(!file.exists("./exdata-data-NEI_data.zip")){
download.file(file_url, destfile="./exdata-data-NEI_data.zip")
unzip("./exdata-data-NEI_data.zip",exdir=".")
}else{
unzip("./exdata-data-NEI_data.zip",exdir=".")
}
}
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
is.installed <- function(pck = NULL){
installed_pck <- as.character(rownames(installed.packages()))
if(is.null(pck)){
installed_pck
}else{
pck %in% installed_pck
}
}
required<- c("plyr", "ggplot2")
for(i in required){
if(is.installed(i)==T){
if(!is.element(i, .packages())) {
library(i, character.only = T, quietly = T,  verbose = F)
}
}else{
install.packages(i, quiet = T,  verbose = F)
library(i, character.only = T, quietly = T,  verbose = F)
}
}
labeled_df <- merge(NEI, SCC, by.x="SCC", by.y= "SCC")
# PLOT 5
## GETTING THE DATA
file_url='https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip'
### Checking the existance of the data
if(!file.exists("./summarySCC_PM25.rds")|!file.exists("./Source_Classification_Code.rds")){
if(!file.exists("./exdata-data-NEI_data.zip")){
download.file(file_url, destfile="./exdata-data-NEI_data.zip")
unzip("./exdata-data-NEI_data.zip",exdir=".")
}else{
unzip("./exdata-data-NEI_data.zip",exdir=".")
}
}
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
is.installed <- function(pck = NULL){
installed_pck <- as.character(rownames(installed.packages()))
if(is.null(pck)){
installed_pck
}else{
pck %in% installed_pck
}
}
required<- c("plyr", "ggplot2")
for(i in required){
if(is.installed(i)==T){
if(!is.element(i, .packages())) {
library(i, character.only = T, quietly = T,  verbose = F)
}
}else{
install.packages(i, quiet = T,  verbose = F)
library(i, character.only = T, quietly = T,  verbose = F)
}
}
labeled_df <- merge(NEI, SCC, by.x="SCC", by.y= "SCC")
mobile_df <- labeled_df[grep("Vehicles$", labeled_df$EI.Sector),]
mobile_bal <- mobile_df[mobile_df$fips=="24510",]
png(filename = "plot5.png", width=1440, height=960)
mobile <- ggplot(data=mobile_bal, aes(year, log(Emissions+0.0000005)))
mobile + geom_point(aes(color = EI.Sector), size = 5 , alpha = 0.3) + facet_wrap(~ EI.Sector, ncol=3, scales="free") + geom_smooth(size = 0.75, color = "black", linetype = 1, method = "glm", se = T)
dev.off()
png(filename = "plot5.png", width=1440, height=960)
mobile <- ggplot(data=mobile_bal, aes(year, log(Emissions+0.0000005)))
mobile + geom_point(aes(color = EI.Sector), size = 5 , alpha = 0.3) + facet_wrap(~ EI.Sector, ncol=2, scales="free") + geom_smooth(size = 0.75, color = "black", linetype = 1, method = "glm", se = T)
dev.off()
png(filename = "plot5.png", width=960, height=480)
mobile <- ggplot(data=mobile_bal, aes(year, log(Emissions+0.0000005)))
mobile + geom_point(aes(color = EI.Sector), size = 5 , alpha = 0.3) + facet_wrap(~ EI.Sector, ncol=2, scales="free") + geom_smooth(size = 0.75, color = "black", linetype = 1, method = "glm", se = T)
dev.off()
png(filename = "plot5.png", width=960, height=720)
mobile <- ggplot(data=mobile_bal, aes(year, log(Emissions+0.0000005)))
mobile + geom_point(aes(color = EI.Sector), size = 5 , alpha = 0.3) + facet_wrap(~ EI.Sector, ncol=2, scales="free") + geom_smooth(size = 0.75, color = "black", linetype = 1, method = "glm", se = T)
dev.off()
setwd("C:/Users/kvj39652/Desktop/ANALYTICS/COURSERA/DATA SCIENCE/COURSES/5. Reproducible Research/Projects/Week2/RepData_PeerAssessment1")
---
title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
### 1. Getting the data:
In order to guarantee the source data is consistent with the analysis performed in this analysis, the existance of the source dataset is checked as well as the compressed file used as a mean of delivery. If the source dataset is not found, it is downloaded from the assaigment webpage and decompressed.
```{r ,echo=TRUE}
file_url='https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip'
if(!file.exists("./activity.csv")){
if(!file.exists("./activity.zip")){
download.file(file_url, destfile="./activity.zip")
unzip("./activity.zip",exdir=".")
}else{
unzip("./activity.zip",exdir=".")
}
}
```
There are three packages necessary to process the dataset: Lubridate, plyr and ggplot2. The following code checks that the packages are installed and loaded:
```{r, echo=TRUE, results="hide", message=FALSE, warning=FALSE}
is.installed <- function(pck = NULL){
installed_pck <- as.character(rownames(installed.packages()))
if(is.null(pck)){
installed_pck
}else{
pck %in% installed_pck
}
}
required<- c("lubridate", "plyr", "ggplot2")
for(i in required){
if(is.installed(i)==T){
if(!is.element(i, .packages())) {
library(i, character.only = T, quietly = T,  verbose = F)
}
}else{
install.packages(i, quiet = T,  verbose = F)
library(i, character.only = T, quietly = T,  verbose = F)
}
}
```
### 2. Preprocessing the data:
For ease of calculations, the date and interval variables are combined to produce a time variable POSIXct by using lubridate:
```{r, echo=TRUE}
steps <- as.data.frame(read.csv("activity.csv", stringsAsFactors=F))
steps$time <- paste(floor(steps$interval/100),round(((steps$interval/100)-floor(steps$interval/100))*100,0),sep=":")
steps$DateTime <- ymd_hms(paste( steps$date, steps$time, "00", sep=" "))
```
## What is mean total number of steps taken per day?
Using plyr to get the sum of steps per day (sum function ignores NA's):
```{r, echo=TRUE}
tot_steps <- ddply(steps, "date", summarize,
sum = sum(steps, na.rm=T))
median <- median(tot_steps$sum)
mean <- mean(tot_steps$sum)
```
### 1. Histogram of the sum of steps per day:
```{r, echo=TRUE}
qplot(sum, data=tot_steps, binwidth=500)
```
### 2. Mean and Median:
The individual tracked in this dataset, takes on average `r round(mean,2)` steps per day. This distribution has a median value of `r median`
## What is the average daily activity pattern?
Using plyr to summarize the average steps per time interval:
```{r, echo=TRUE}
ave_steps <- ddply(steps, "interval", summarize,
ave = round(mean(steps, na.rm=T),2))
```
### 1. Time-Series plot of the averge number of steps per time interval:
```{r, echo=TRUE}
plot(ave_steps$interval, ave_steps$ave, type = "l")
```
### 2. The time interval with most steps on average:
```{r, echo=TRUE}
max_interval <- ave_steps[ave_steps$ave==max(ave_steps$ave),"interval"]
max_interval <- paste(floor(max_interval/100),round(((max_interval/100)-floor(max_interval/100))*100,0), sep=":")
```
The individual being tracked in this datataset takes the largest amount of steps on average at `r max_interval`. It is possible that the individual commutes using a bike or walking. It is also possible that he/she exercises as part of a morning routine.
## Imputing missing values
### 1. Number of NAs:
```{r, echo=TRUE}
steps$nas <- is.na(steps$steps)
tot_na <- sum(steps$nas)
```
The total number of NAs for the steps variable is `r tot_na`
### 2. Filling out the NAs:
The idea here is to fill out the NA's with the average number of steps for the corresponding time interval as observed in the global dataset:
```{r, echo=TRUE}
new_steps <- steps
for(k in seq_along(new_steps$nas)){
if(new_steps$nas[k]==T){
new_steps$steps[k] <- ave_steps[ave_steps$interval==new_steps$interval[k],"ave"]
}
}
new_steps$nas <- is.na(new_steps$steps)
```
### 3. The New Dataset:
The OLD dataset
```{r, echo=TRUE}
head(steps, 10)
```
The NEW dataset
```{r, echo=TRUE}
head(new_steps, 10)
```
### 4. Histogram of the new dataset:
```{r, echo=TRUE}
tot_new_steps <- ddply(new_steps, "date", summarize,
sum = sum(steps))
new_median <- median(tot_new_steps$sum)
new_mean <- round(mean(tot_new_steps$sum),2)
qplot(sum, data=tot_new_steps, binwidth=500)
```
The new dataset has a value for the mean steps taken in a day of `r as.character(new_mean)` and a median of `r as.character(new_median)`, which differs from the original values (mean:`r round(mean,2)`, median:`r median`) by `r round(new_mean-mean,2)` and `r round(new_median-median,2)` respectively.
## Are there differences in activity patterns between weekdays and weekends?
### 1. A new factor variable:
Creating a factor variable with 2 levels: "weekday" & "weekend":
```{r, echo=TRUE}
new_steps$day <- wday(new_steps$DateTime,label=F)
new_steps$week <- "weekend"
new_steps[new_steps$day<=5,"week"] <- "weekday"
new_steps$week <- as.factor(new_steps$week)
Week_ave_steps <- ddply(new_steps, c("interval","week"), summarize,
ave = round(mean(steps, na.rm=T),2))
```
### 2. Time-Series plot containing pannels for "weekday" and "weekend" averages:
```{r, echo=TRUE}
qplot(interval,ave,data=Week_ave_steps, facets = week~., geom="line")
```
There seems to be more activity on the weekends as measured by the average number of steps.
This is an overylay of the average steps taken during weekdays and on the weekends:
```{r, echo=TRUE}
g <- ggplot(Week_ave_steps, aes(interval,ave))
g + geom_line(aes(color = week), size=1,  alpha = 1/2)
```
Also, a violin plot that clearly shows more activity on the weekends:
```{r, echo=TRUE}
v <-ggplot(Week_ave_steps, aes(week,ave))
v + geom_violin(alpha=0.5, color="gray")+geom_jitter(alpha=0.5, aes(color=week),
position = position_jitter(width = 0.1))+coord_flip()
```
View(steps)
pnorm(1100,75,.95)
qnorm(95, mean=1100, sd=75)
qnorm(.95, mean=1100, sd=75)
pnorm(.95, mean=1100, sd=75)
dnorm(.95, mean=1100, sd=75)
qnorm(.95, mean=1100, sd=75)
qnorm(.95, mean=1100, sd=(75/10))
qnorm(.95, mean=1100, sd=(75/(99^-0.5))
)
qnorm(.95, mean=1100, sd=(75/sqrt(99)))
pbinom(3, size=5, prob=0.5, lower.tail=F)
pbinom(4, size=5, prob=0.5, lower.tail=F)
choose(4,5)*0.5^5 + choose(5,5)*0.5^5
choose(5,4)*0.5^5 + choose(5,5)*0.5^5
15 + c(-1, 1)* (10/sqrt(99))
ppois(10, lambda=5*3)
